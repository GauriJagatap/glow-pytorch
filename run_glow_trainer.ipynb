{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import vision\n",
    "from docopt import docopt\n",
    "from torchvision import transforms\n",
    "from glow.builder_new import build\n",
    "from glow.trainer import Trainer\n",
    "from glow.config import JsonConfig\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glow.models_new import Glow\n",
    "from glow import learning_rate_schedule\n",
    "from torch.utils.data import DataLoader\n",
    "from glow import thops\n",
    "from glow.utils import get_proper_device\n",
    "import datetime\n",
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6\n"
     ]
    }
   ],
   "source": [
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to parse all image attrs\n",
      "Find 202599 images, with 40 attrs\n",
      "number of batches: 22511\n"
     ]
    }
   ],
   "source": [
    "hparams = JsonConfig('./hparams/celeba.json')\n",
    "dataset_name = 'celeba'\n",
    "dataset_root = 'dataset/CelebA'\n",
    "dataset = vision.Datasets[dataset_name]\n",
    "# set transform of dataset\n",
    "transform = transforms.Compose([\n",
    "        transforms.CenterCrop(hparams.Data.center_crop),\n",
    "        transforms.Resize(hparams.Data.resize),\n",
    "        transforms.ToTensor()])\n",
    "dataset = dataset(dataset_root, transform=transform)\n",
    "data_loader = DataLoader(dataset,batch_size=hparams.Train.batch_size,shuffle=False,drop_last=True)\n",
    "num_batches = len(data_loader)\n",
    "print('number of batches:', num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize Glow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Builder]: Found 1 gpu\n",
      "[Builder]: cuda:1 is not found, ignore.\n",
      "[Builder]: cuda:2 is not found, ignore.\n",
      "[Builder]: cuda:3 is not found, ignore.\n"
     ]
    }
   ],
   "source": [
    "Glownet = Glow(hparams)\n",
    "Glownet.device = hparams.Device.glow\n",
    "devices = get_proper_device(hparams.Device.glow)\n",
    "if len(devices) > 0:\n",
    "    device = Glownet.device[0]\n",
    "    Glownet = Glownet.to(device)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(datetime.datetime.now())\n",
    "date = date[:date.rfind(\":\")].replace(\"-\", \"\")\\\n",
    "                                     .replace(\":\", \"\")\\\n",
    "                                     .replace(\" \", \"_\")\n",
    "log_dir = os.path.join(hparams.Dir.log_root, \"log_\" + date)\n",
    "checkpoints_dir = os.path.join(log_dir, \"checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_name = \"default\"\n",
    "schedule_args = {}\n",
    "if \"Schedule\" in hparams.Optim:\n",
    "    schedule_name = hparams.Optim.Schedule.name\n",
    "    schedule_args = hparams.Optim.Schedule.args.to_dict()\n",
    "if not (\"init_lr\" in schedule_args):\n",
    "        schedule_args[\"init_lr\"] = hparams.Optim.args.lr\n",
    "assert schedule_args[\"init_lr\"] == hparams.Optim.args.lr,\\\n",
    "                \"Optim lr {} != Schedule init_lr {}\".format(hparams.Optim.args.lr, schedule_args[\"init_lr\"])\n",
    "lrschedule = {\n",
    "                \"func\": getattr(learning_rate_schedule, schedule_name),\n",
    "                \"args\": schedule_args\n",
    "              }\n",
    "opt_params = hparams.Optim.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_name = hparams.Optim.name\n",
    "if optim_name == 'adam':\n",
    "    optimizer = torch.optim.Adam(Glownet.parameters(), opt_params['lr'], opt_params['betas'], opt_params['eps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train Glow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.: 0\n",
      "epoch no. 0 , batch no. 0  of  22511\n",
      "generative loss: 0.14936174\n",
      "norm of gradients: 82.2569327122766\n",
      "epoch no. 0 , batch no. 20  of  22511\n",
      "generative loss: 0.4281676\n",
      "norm of gradients: 102.09868519696306\n",
      "epoch no. 0 , batch no. 37  of  22511\r"
     ]
    }
   ],
   "source": [
    "# initialize global_step : cumulative no. of optimizer steps = no. epochs * no. batches\n",
    "global_step = 0 \n",
    "generative_loss_perNepoch = []\n",
    "classification_loss_perNepoch = []\n",
    "check_images = False\n",
    "for epoch in range(1):\n",
    "    print(\"epoch no.:\", epoch)\n",
    "    for i_batch, batch in enumerate(data_loader):\n",
    "        print('epoch no.',epoch,', batch no.',i_batch,' of ', num_batches, end='\\r')\n",
    "        \n",
    "        # update learning rate\n",
    "        lr = lrschedule[\"func\"](global_step=0,**lrschedule[\"args\"])\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "        # initialize optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # send data to device and extract\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        # extract images x\n",
    "        x = batch[\"x\"]\n",
    "        # extract labels y, y_onehot\n",
    "        y = None\n",
    "        y_onehot = None\n",
    "        if hparams.Glow.y_condition:\n",
    "            if hparams.Criterion.y_condition == \"multi-classes\":\n",
    "                assert \"y_onehot\" in batch, \"multi-classes ask for `y_onehot` (torch.FloatTensor onehot)\"\n",
    "                y_onehot = batch[\"y_onehot\"]\n",
    "            elif hparams.Criterion.y_condition == \"single-class\":\n",
    "                assert \"y\" in batch, \"single-class ask for `y` (torch.LongTensor indexes)\"\n",
    "                y = batch[\"y\"]\n",
    "                y_onehot = thops.onehot(y, num_classes=hparams.Glow.y_classes)\n",
    "\n",
    "        # initialize ActNorm (first iteration only)\n",
    "        if global_step == 0:\n",
    "            Glownet(x[:hparams.Train.batch_size // len(devices), ...],y_onehot[:hparams.Train.batch_size // len(devices), ...] if y_onehot is not None else None)\n",
    "        \n",
    "        # parallel \n",
    "        if len(devices) > 1 and not hasattr(Glownet, \"module\"):\n",
    "            print(\"[Parallel] move to {}\".format(self.devices))\n",
    "            self.graph = torch.nn.parallel.DataParallel(self.graph, self.devices, self.devices[0])\n",
    "            \n",
    "        # forward phase\n",
    "        z, nll, y_logits = Glownet(x=x, y_onehot=y_onehot)\n",
    "        \n",
    "        # construct genetative loss\n",
    "        loss_generative = Glownet.loss_generative(nll)\n",
    "        \n",
    "        # construct classification loss\n",
    "        loss_classes = 0\n",
    "        if hparams.Glow.y_condition:\n",
    "            loss_classes = (Glownet.loss_multi_classes(y_logits, y_onehot)\n",
    "                            if self.y_criterion == \"multi-classes\" else\n",
    "                                    Glownet.loss_class(y_logits, y))\n",
    "        \n",
    "        #construct overall loss function\n",
    "        if global_step % hparams.Train.scalar_log_gap == 0:\n",
    "            generative_loss_perNepoch.append(loss_generative)\n",
    "            print(\"\\ngenerative loss:\", loss_generative.detach().cpu().numpy())\n",
    "            if hparams.Glow.y_condition:\n",
    "                generative_loss_perNepoch.append(loss_generative)\n",
    "                print(\"classification loss:\", loss_classes)\n",
    "        loss = loss_generative + loss_classes * hparams.Train.weight_y\n",
    "\n",
    "        # backpropagate gradients\n",
    "        Glownet.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip gradients\n",
    "        if hparams.Train.max_grad_clip is not None and hparams.Train.max_grad_clip > 0:\n",
    "            torch.nn.utils.clip_grad_value_(Glownet.parameters(), hparams.Train.max_grad_clip)\n",
    "        if hparams.Train.max_grad_norm is not None and hparams.Train.max_grad_norm > 0:\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(Glownet.parameters(), hparams.Train.max_grad_norm)\n",
    "            if global_step % hparams.Train.scalar_log_gap == 0:\n",
    "                print(\"norm of gradients:\", grad_norm)\n",
    "        \n",
    "        # gradient step\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # checkpoints\n",
    "        if global_step % hparams.Train.checkpoints_gap == 0 and global_step > 0:\n",
    "            save(global_step=global_step,\n",
    "                         graph=Glownet,\n",
    "                         optim=optimizer,\n",
    "                         pkg_dir=checkpoints_dir,\n",
    "                         is_best=True,\n",
    "                         max_checkpoints=hparams.Train.max_checkpoints)\n",
    "        \n",
    "        # check generated images and plot\n",
    "        if check_images:\n",
    "            if global_step % hparams.Train.plot_gap == 0:\n",
    "                img = Glownet(z=z, y_onehot=y_onehot, reverse=True)\n",
    "                # img = torch.clamp(img, min=0, max=1.0)\n",
    "                if hparams.Glow.y_condition:\n",
    "                    if hparams.Criterion.y_condition == \"multi-classes\":\n",
    "                        y_pred = torch.sigmoid(y_logits)\n",
    "                    elif hparams.Criterion.y_condition == \"single-class\":\n",
    "                        y_pred = thops.onehot(torch.argmax(F.softmax(y_logits, dim=1), dim=1, keepdim=True),\n",
    "                                                      self.y_classes)\n",
    "                    y_true = y_onehot\n",
    "\n",
    "                for bi in range(min([len(img), 4])):\n",
    "                    self.writer.add_image(\"0_reverse/{}\".format(bi), torch.cat((img[bi], batch[\"x\"][bi]), dim=1), self.global_step)\n",
    "                    if hparams.Glow.y_condition:\n",
    "                        self.writer.add_image(\"1_prob/{}\".format(bi), plot_prob([y_pred[bi], y_true[bi]], [\"pred\", \"true\"]), self.global_step)\n",
    "\n",
    "\n",
    "            # inference\n",
    "            if hparams.Train.inference_gap is not None:\n",
    "                if global_step % hparams.Train.inference_gap == 0:\n",
    "                    img = Glownet(z=None, y_onehot=y_onehot, eps_std=0.5, reverse=True)\n",
    "                    for bi in range(min([len(img), 4])):\n",
    "                        self.writer.add_image(\"2_sample/{}\".format(bi), img[bi], self.global_step)\n",
    "\n",
    "        # global step\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_images:\n",
    "    self.writer.export_scalars_to_json(os.path.join(self.log_dir, \"all_scalars.json\"))\n",
    "    self.writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
